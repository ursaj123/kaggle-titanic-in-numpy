{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "   PassengerId  Pclass                                          Name     Sex  \\\n",
      "0          892       3                              Kelly, Mr. James    male   \n",
      "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
      "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
      "3          895       3                              Wirz, Mr. Albert    male   \n",
      "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
      "\n",
      "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
      "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
      "1  47.0      1      0   363272   7.0000   NaN        S  \n",
      "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
      "3  27.0      0      0   315154   8.6625   NaN        S  \n",
      "4  22.0      1      1  3101298  12.2875   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "# reding the dataset \n",
    "train_data = pd.read_csv('train.csv')\n",
    "pred_data = pd.read_csv('test.csv')\n",
    "print(train_data.head())\n",
    "print(pred_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "passengerId = np.array(pred_data['PassengerId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "    \n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# checking if values are nan in any column of the dataset\n",
    "print(train_data.isnull().sum())#total number of nan values in column\n",
    "print(\"    \")\n",
    "print(pred_data.isnull().sum())\n",
    "# there are a lot of missing values in cabin this column so we are going to drop this column for creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
      "0         0       3    male  22.0      1      0   7.2500        S\n",
      "1         1       1  female  38.0      1      0  71.2833        C\n",
      "2         1       3  female  26.0      0      0   7.9250        S\n",
      "3         1       1  female  35.0      1      0  53.1000        S\n",
      "4         0       3    male  35.0      0      0   8.0500        S\n",
      "   Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
      "0       3    male  34.5      0      0   7.8292        Q\n",
      "1       3  female  47.0      1      0   7.0000        S\n",
      "2       2    male  62.0      0      0   9.6875        Q\n",
      "3       3    male  27.0      0      0   8.6625        S\n",
      "4       3  female  22.0      1      1  12.2875        S\n"
     ]
    }
   ],
   "source": [
    "# droppimg the columns which i thought would be of no use or having a large number of nan values\n",
    "train_data = train_data.drop(['PassengerId','Name','Ticket','Cabin'],axis=1)\n",
    "print(train_data.head())\n",
    "pred_data = pred_data.drop(['PassengerId','Name','Ticket','Cabin'],axis=1)\n",
    "print(pred_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can't drop age column so we filled it with mean value otherwise dropping rows corresponding to nan values would result in loss of a lot of data\n",
    "# for training set\n",
    "mean_value = train_data['Age'].mean()\n",
    "train_data['Age'].fillna(value=mean_value,inplace=True)\n",
    "# for prediction set\n",
    "mean_value = pred_data['Age'].mean()\n",
    "pred_data['Age'].fillna(value=mean_value,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling one nan value with the mean in the pred set\n",
    "mean_value = pred_data['Fare'].mean()\n",
    "pred_data['Fare'].fillna(value=mean_value,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived    0\n",
      "Pclass      0\n",
      "Sex         0\n",
      "Age         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Fare        0\n",
      "Embarked    2\n",
      "dtype: int64\n",
      "       \n",
      "Pclass      0\n",
      "Sex         0\n",
      "Age         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Fare        0\n",
      "Embarked    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>34.50000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>47.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>62.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>27.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>22.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>30.27259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>39.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>38.50000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>30.27259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>30.27259</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass     Sex       Age  SibSp  Parch      Fare Embarked\n",
       "0         3    male  34.50000      0      0    7.8292        Q\n",
       "1         3  female  47.00000      1      0    7.0000        S\n",
       "2         2    male  62.00000      0      0    9.6875        Q\n",
       "3         3    male  27.00000      0      0    8.6625        S\n",
       "4         3  female  22.00000      1      1   12.2875        S\n",
       "..      ...     ...       ...    ...    ...       ...      ...\n",
       "413       3    male  30.27259      0      0    8.0500        S\n",
       "414       1  female  39.00000      0      0  108.9000        C\n",
       "415       3    male  38.50000      0      0    7.2500        S\n",
       "416       3    male  30.27259      0      0    8.0500        S\n",
       "417       3    male  30.27259      1      1   22.3583        C\n",
       "\n",
       "[418 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for nan values again\n",
    "print(train_data.isnull().sum())\n",
    "print(\"       \")\n",
    "print(pred_data.isnull().sum())\n",
    "pred_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>889 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass     Sex        Age  SibSp  Parch     Fare Embarked\n",
       "0           0       3    male  22.000000      1      0   7.2500        S\n",
       "1           1       1  female  38.000000      1      0  71.2833        C\n",
       "2           1       3  female  26.000000      0      0   7.9250        S\n",
       "3           1       1  female  35.000000      1      0  53.1000        S\n",
       "4           0       3    male  35.000000      0      0   8.0500        S\n",
       "..        ...     ...     ...        ...    ...    ...      ...      ...\n",
       "886         0       2    male  27.000000      0      0  13.0000        S\n",
       "887         1       1  female  19.000000      0      0  30.0000        S\n",
       "888         0       3  female  29.699118      1      2  23.4500        S\n",
       "889         1       1    male  26.000000      0      0  30.0000        C\n",
       "890         0       3    male  32.000000      0      0   7.7500        Q\n",
       "\n",
       "[889 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can drop 2 rows as they are having nan values in embarked column \n",
    "train_data = train_data.dropna(axis=0)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>889 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass     Sex        Age  SibSp  Parch     Fare Embarked\n",
       "0         3    male  22.000000      1      0   7.2500        S\n",
       "1         1  female  38.000000      1      0  71.2833        C\n",
       "2         3  female  26.000000      0      0   7.9250        S\n",
       "3         1  female  35.000000      1      0  53.1000        S\n",
       "4         3    male  35.000000      0      0   8.0500        S\n",
       "..      ...     ...        ...    ...    ...      ...      ...\n",
       "886       2    male  27.000000      0      0  13.0000        S\n",
       "887       1  female  19.000000      0      0  30.0000        S\n",
       "888       3  female  29.699118      1      2  23.4500        S\n",
       "889       1    male  26.000000      0      0  30.0000        C\n",
       "890       3    male  32.000000      0      0   7.7500        Q\n",
       "\n",
       "[889 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separating y_train from the dataset as it is not having the categorical variables\n",
    "train_X_data = train_data.iloc[:,1:]\n",
    "y = np.array(train_data['Survived'])\n",
    "train_X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct_train = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0,1,-1])], remainder='passthrough')\n",
    "train_X_data = np.array(ct_train.fit_transform(train_X_data))\n",
    "ct_pred = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0,1,-1])], remainder='passthrough')\n",
    "pred_data = np.array(ct_pred.fit_transform(pred_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2    3    4    5    6    7     8    9   10       11\n",
      "0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0  22.0  1.0  0.0   7.2500\n",
      "1  1.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  38.0  1.0  0.0  71.2833\n",
      "2  0.0  0.0  1.0  1.0  0.0  0.0  0.0  1.0  26.0  0.0  0.0   7.9250\n",
      "3  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  35.0  1.0  0.0  53.1000\n",
      "4  0.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0  35.0  0.0  0.0   8.0500      \n",
      "     0    1    2    3    4    5    6    7     8    9   10       11\n",
      "0  0.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  34.5  0.0  0.0   7.8292\n",
      "1  0.0  0.0  1.0  1.0  0.0  0.0  0.0  1.0  47.0  1.0  0.0   7.0000\n",
      "2  0.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0  62.0  0.0  0.0   9.6875\n",
      "3  0.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0  27.0  0.0  0.0   8.6625\n",
      "4  0.0  0.0  1.0  1.0  0.0  0.0  0.0  1.0  22.0  1.0  1.0  12.2875\n"
     ]
    }
   ],
   "source": [
    "train_X_data = pd.DataFrame(train_X_data)\n",
    "print(train_X_data.head(),\"     \")\n",
    "pred_data = pd.DataFrame(pred_data)\n",
    "print(pred_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.    ,  0.    ,  1.    , ...,  0.    ,  0.    ,  7.8292],\n",
       "       [ 0.    ,  0.    ,  1.    , ...,  1.    ,  0.    ,  7.    ],\n",
       "       [ 0.    ,  1.    ,  0.    , ...,  0.    ,  0.    ,  9.6875],\n",
       "       ...,\n",
       "       [ 0.    ,  0.    ,  1.    , ...,  0.    ,  0.    ,  7.25  ],\n",
       "       [ 0.    ,  0.    ,  1.    , ...,  0.    ,  0.    ,  8.05  ],\n",
       "       [ 0.    ,  0.    ,  1.    , ...,  1.    ,  1.    , 22.3583]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_data = np.array(train_X_data)\n",
    "train_X_data\n",
    "X_pred = np.array(pred_data)\n",
    "X_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(y.shape[0]):\n",
    "    if y[i]==0:\n",
    "        y[i] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_X_data,y,test_size=0.01,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(880, 12)\n",
      "(880,)\n",
      "(9, 12)\n",
      "(9,)\n",
      "(418, 12)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(pred_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### X_TRAIN AND Y_TRAIN ARE HERE. NOW WE HAVE TO APPLY SVM ALGORITHM TO CREATE A MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((np.ones((880,1)),X_train),axis=1)\n",
    "X_test = np.concatenate((np.ones((9,1)),X_test),axis=1)\n",
    "X_pred = np.concatenate((np.ones((X_pred.shape[0],1)),X_pred),axis=1)\n",
    "X_pred = X_pred.T\n",
    "X_train = X_train.T \n",
    "X_test = X_test.T\n",
    "y_train = y_train.reshape((1,880))\n",
    "y_test = y_test.reshape((1,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 880)\n",
      "(13, 9)\n",
      "(1, 880)\n",
      "(1, 9)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  TRYING FOR SVM ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(W,X):\n",
    "    return np.dot(W,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(W,X,y,lambd=0):\n",
    "    m = y.shape[1]\n",
    "    cost = (lambd/2)*np.square(np.linalg.norm(W)) + np.sum(np.maximum(np.zeros((1,m)), 1 - np.multiply(y, func(W,X))))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grads(W,X,y,lambd=0):\n",
    "    m = y.shape[1]\n",
    "    W_term_grad = lambd*W\n",
    "    max_term_grad = np.zeros((1, X.shape[0]))\n",
    "    for i in range(m):\n",
    "        if 1 - y[:,i]*np.dot(W,X[:,i]) > 0:\n",
    "            max_term_grad = max_term_grad - y[:,i]*X[:,i]\n",
    "    grad = W_term_grad + max_term_grad\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(W,X,lambd=0):\n",
    "    model_output = func(W,X)\n",
    "    m = X.shape[1]\n",
    "    for i in range(m):\n",
    "        if model_output[0,i]>=0:\n",
    "            model_output[0,i] = 1\n",
    "        else:\n",
    "            model_output[0,i] = -1\n",
    "    return model_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred, true_labels):\n",
    "    m = true_labels.shape[1]\n",
    "    acc = np.sum(pred==true_labels)\n",
    "    return acc/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, y, num_epochs, lr,c, lambd=0):\n",
    "    costs = []\n",
    "    n = X.shape[0]\n",
    "    m = X.shape[1]\n",
    "    W = np.zeros((1,n), dtype=np.float64)*c\n",
    "    for epoch in range(num_epochs):\n",
    "        model_output = func(W,X)\n",
    "        grad = grads(W,X,y,lambd)\n",
    "        W = W - lr*grad\n",
    "        if epoch%100==0:\n",
    "            cost = compute_cost(W,X,y,lambd)\n",
    "            costs.append(cost)\n",
    "            print(\"Loss after \", epoch, \" iterations is \",cost, \", train_acc \",accuracy(predict(W,X,lambd), y))\n",
    "    plt.plot(np.arange(len(costs)),costs)\n",
    "    plt.title(\"Loss vs num_iterations graph\")\n",
    "    plt.xlabel(\"Number of iterations (per hundred)\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after  0  iterations is  814.1258274152975 , train_acc  0.6818181818181818\n",
      "Loss after  100  iterations is  634.6551264344951 , train_acc  0.675\n",
      "Loss after  200  iterations is  625.7661097376496 , train_acc  0.6875\n",
      "Loss after  300  iterations is  617.0500731611863 , train_acc  0.6909090909090909\n",
      "Loss after  400  iterations is  608.5425672926611 , train_acc  0.6954545454545454\n",
      "Loss after  500  iterations is  600.280205306746 , train_acc  0.7\n",
      "Loss after  600  iterations is  592.236352183382 , train_acc  0.7011363636363637\n",
      "Loss after  700  iterations is  584.6858528982546 , train_acc  0.6988636363636364\n",
      "Loss after  800  iterations is  577.1389251832705 , train_acc  0.7011363636363637\n",
      "Loss after  900  iterations is  570.0634161166315 , train_acc  0.7056818181818182\n",
      "Loss after  1000  iterations is  563.8341634060699 , train_acc  0.7079545454545455\n",
      "Loss after  1100  iterations is  557.8015936033627 , train_acc  0.7079545454545455\n",
      "Loss after  1200  iterations is  552.1326018774649 , train_acc  0.7090909090909091\n",
      "Loss after  1300  iterations is  546.5675404963932 , train_acc  0.7090909090909091\n",
      "Loss after  1400  iterations is  541.2945673985726 , train_acc  0.7147727272727272\n",
      "Loss after  1500  iterations is  536.4992534199781 , train_acc  0.7170454545454545\n",
      "Loss after  1600  iterations is  531.9585555150251 , train_acc  0.7204545454545455\n",
      "Loss after  1700  iterations is  527.5902120215038 , train_acc  0.7193181818181819\n",
      "Loss after  1800  iterations is  523.8518943856093 , train_acc  0.7204545454545455\n",
      "Loss after  1900  iterations is  520.3557370423853 , train_acc  0.7227272727272728\n",
      "Loss after  2000  iterations is  517.0568333359234 , train_acc  0.725\n",
      "Loss after  2100  iterations is  513.8934215487728 , train_acc  0.725\n",
      "Loss after  2200  iterations is  510.8925878431955 , train_acc  0.7261363636363637\n",
      "Loss after  2300  iterations is  508.0279375127135 , train_acc  0.7284090909090909\n",
      "Loss after  2400  iterations is  505.2778863331119 , train_acc  0.7329545454545454\n",
      "Loss after  2500  iterations is  502.6931401746568 , train_acc  0.7363636363636363\n",
      "Loss after  2600  iterations is  500.4829630683573 , train_acc  0.7420454545454546\n",
      "Loss after  2700  iterations is  498.08330674798134 , train_acc  0.7420454545454546\n",
      "Loss after  2800  iterations is  496.11462486856504 , train_acc  0.7443181818181818\n",
      "Loss after  2900  iterations is  494.0384169397305 , train_acc  0.7454545454545455\n",
      "Loss after  3000  iterations is  492.06977099435295 , train_acc  0.7477272727272727\n",
      "Loss after  3100  iterations is  489.9103222293045 , train_acc  0.75\n",
      "Loss after  3200  iterations is  487.94883710559026 , train_acc  0.7522727272727273\n",
      "Loss after  3300  iterations is  486.3418811846549 , train_acc  0.7534090909090909\n",
      "Loss after  3400  iterations is  484.1891039922475 , train_acc  0.7636363636363637\n",
      "Loss after  3500  iterations is  482.3520691213575 , train_acc  0.7693181818181818\n",
      "Loss after  3600  iterations is  480.5294477425441 , train_acc  0.7715909090909091\n",
      "Loss after  3700  iterations is  478.7423454420734 , train_acc  0.7704545454545455\n",
      "Loss after  3800  iterations is  477.0102046717975 , train_acc  0.775\n",
      "Loss after  3900  iterations is  475.3016273513871 , train_acc  0.7761363636363636\n",
      "Loss after  4000  iterations is  473.6271086792706 , train_acc  0.7795454545454545\n",
      "Loss after  4100  iterations is  471.95348334725094 , train_acc  0.7818181818181819\n",
      "Loss after  4200  iterations is  470.641883277277 , train_acc  0.7818181818181819\n",
      "Loss after  4300  iterations is  469.0723113236992 , train_acc  0.7829545454545455\n",
      "Loss after  4400  iterations is  467.37254550254 , train_acc  0.7852272727272728\n",
      "Loss after  4500  iterations is  465.74584891132577 , train_acc  0.8\n",
      "Loss after  4600  iterations is  464.1576631195166 , train_acc  0.8\n",
      "Loss after  4700  iterations is  462.5341143884893 , train_acc  0.8022727272727272\n",
      "Loss after  4800  iterations is  460.988492931021 , train_acc  0.803409090909091\n",
      "Loss after  4900  iterations is  459.3530453866293 , train_acc  0.803409090909091\n",
      "Loss after  5000  iterations is  457.822039051541 , train_acc  0.8045454545454546\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "W = model(X_train, y_train, num_epochs=5001, lr = 1e-6, c=0.001, lambd=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(predict(W,X_test,lambd=10),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predict(W,X_pred,lambd=10).astype(np.int64)\n",
    "m = X_pred.shape[1]\n",
    "for i in range(m):\n",
    "    if pred[0,i]==-1:\n",
    "        pred[0,i]=0\n",
    "passengerId = passengerId.reshape((1,pred.shape[1]))\n",
    "ans = pd.DataFrame(np.concatenate((passengerId.T,pred.T),axis=1))\n",
    "ans.columns = ['PassengerId','Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = ans.to_csv(\"Submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For more accuarcy we can add kernel trick to it "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
